[
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Summary Report: \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Event Information Date: Friday, October 3rd, 2025 Time: 2:00 PM - 4:30 PM Location: AWS Event Hall, L26 Bitexco Tower, HCMC Organizer: AWS GenAI Builder Club Coordinators: Diem My, Dai Truong, Dinh Nguyen Event Objectives Explore how generative AI transforms the software development lifecycle Demonstrate AI-powered development workflow from architecture to maintenance Present Amazon Q Developer and Kiro for AI-assisted development Show how AI automation increases productivity and enables focus on creative tasks Provide hands-on experience with AI-driven development tools and methodologies Speakers \u0026amp; Schedule 2:00 PM - 2:15 PM: Welcoming 2:15 PM - 3:30 PM: AI-Driven Development Life Cycle Overview \u0026amp; Amazon Q Developer Demonstration\nToan Huynh – Instructor, AI-Driven Development Specialist 3:30 PM - 3:45 PM: Break 3:45 PM - 4:30 PM: Kiro Demonstration\nMy Nguyen – Instructor, AI Development Tools Expert Key Highlights AI-DLC Standard Development Workflow The workshop introduced a comprehensive 4-phase development workflow:\nREQUIREMENT: Product Owner defines business needs and user stories DESIGN: Software Architect creates system design and architecture IMPLEMENTATION: Software Engineers develop and code the solution DEPLOYMENT: DevOps team handles deployment and operations This represents a spec-driven development approach where each phase is clearly defined and AI-assisted.\nAI-DLC Steps Framework The methodology follows a structured approach with multiple components:\nRequirements: Initial business and technical requirements gathering Vibe Coding: AI-assisted rapid prototyping and code generation Code: Production-ready code development with AI support Three Main Phases:\nInception: Project planning, user stories, and initial setup Construction: Domain design, logical design, and implementation Operation: Deployment, testing, and maintenance AI-Driven Development Lifecycle (9 Steps) The workshop detailed a comprehensive 9-step process:\nBuild Context on Existing Codes - Analyze current codebase Elaborate Intent with User Stories - Define clear requirements Plan with Units of Work - Break down into manageable tasks Domain Model (Component Model) - Design system architecture Generate code \u0026amp; Test - AI-assisted code generation Add architectural components - Integrate system components Deploy with IaaC \u0026amp; tests - Infrastructure as Code deployment Deploy in production with - Production deployment strategies Manage incidents - Ongoing maintenance and issue resolution Project Structure and Organization The workshop demonstrated proper repository organization:\nRoot Directory: Contains multiple independent Flask applications .kiro/ folder: Contains specifications, steering rules, and settings requirements.txt: Shared dependencies for all applications Application Structure follows consistent patterns:\nFlask environment configuration Application file with routes and logic Database models (if applicable) Static assets (CSS, JS, Images) HTML templates Prompt Engineering for Development The workshop emphasized the importance of effective prompt templates:\nRole Definition: \u0026ldquo;You are an expert software architect\u0026hellip;\u0026rdquo; Task Specification: Clear, actionable instructions for AI Context Provision: Relevant background information Output Format: Structured markdown with checkboxes for tracking Iterative Refinement: Process for improving and validating AI responses Key Takeaways AI-Assisted Development Philosophy Human-AI Collaboration: Balance between AI capabilities and human oversight Iterative Validation: Always validate and review AI-generated code before implementation Context-Aware Prompting: Provide sufficient context for AI to generate relevant solutions Structured Approach: Follow systematic methodology rather than ad-hoc AI usage Technical Implementation Modular Architecture: Each application component should be independently deployable Specification-Driven: Use clear specifications and steering rules for consistency Template-Based Development: Leverage proven patterns and templates for faster development Infrastructure as Code: Automate deployment and infrastructure management Project Management with AI Unit-Based Planning: Break complex projects into manageable, AI-assistable units User Story Elaboration: Use AI to expand and clarify business requirements Domain Modeling: Apply AI to create comprehensive component models Continuous Integration: Implement automated testing and deployment pipelines Applying to Work Implement AI-DLC Framework: Apply the 9-step process to current development projects Create Prompt Templates: Develop standardized prompts for common development tasks Establish Project Structure: Adopt the modular Flask application architecture shown Integrate AI Tools: Use AI for code generation, testing, and documentation Practice Spec-Driven Development: Start with clear specifications before implementation Build Context Libraries: Maintain reusable components and patterns for AI assistance Event Experience Attending the \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; session at AWS Event Hall, Bitexco Tower was an exceptional experience that demonstrated how generative AI is transforming software development. Key experiences included:\nLearning from AWS GenAI Builder Club experts Toan Huynh provided comprehensive insights into Amazon Q Developer and AI-Driven Development Lifecycle methodology during the 75-minute main session. My Nguyen delivered an excellent demonstration of Kiro and its applications in AI-assisted development in the final session. The coordinators Diem My, Dai Truong, and Dinh Nguyen ensured smooth workshop execution and networking opportunities. Understanding AI transformation in software engineering Learned how generative AI reimagines the entire software development process from learning and planning to deployment and management. The 9-step AI-DLC process provided a clear framework for integrating AI throughout the entire software development lifecycle. Understanding how AI automates undifferentiated heavy lifting tasks and enables developers to focus on higher-value, creative work. Hands-on AI-assisted development Learned practical prompt engineering techniques for software development tasks. Experienced how to structure project repositories for AI-friendly development. Understood the importance of context provision when working with AI coding assistants. Practiced creating modular Flask applications with proper separation of concerns. Technical architecture insights The standard development workflow (Requirement → Design → Implementation → Deployment) provided a solid foundation for AI integration. Learned about role-based development where Product Owners, Software Architects, and Engineers collaborate with AI tools. Understanding domain modeling and component architecture in an AI-assisted environment. Practical implementation strategies Saw real examples of AI-generated code and learned validation techniques. Understood how to break down complex projects into manageable AI-assistable units. Learned about Infrastructure as Code (IaaC) deployment strategies with AI support. Gained insights into incident management in AI-assisted development environments. Collaboration and workflow optimization The workshop emphasized human-AI collaboration rather than AI replacement of developers. Learned the importance of iterative validation and human oversight in AI-generated solutions. Understanding how AI can enhance team productivity while maintaining code quality and security. Lessons learned AI tools require structured approaches and clear methodologies to be effective in professional development. Prompt engineering is a crucial skill for modern developers working with AI assistants. The context-aware development approach significantly improves AI assistance quality. Template-based development patterns can accelerate AI-assisted project delivery. Overall, this workshop not only provided practical AI development skills but also established a systematic approach to integrating AI tools into professional software development workflows. The structured methodology ensures that AI enhances rather than complicates the development process.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "FROM CURIOUS TO BUILD REAL-LIFE AWS PROJECT : MY CLOUD JOURNEY WITH AWS EDUCATE This blog post shared a story of Nikhil Nareddula - who once had no foundation about cloud computing, but with AWS Educate he has buit knowlegde, skills and confidently launchs real-life AWS projects. The author emphasizes the role of freedom and life long learning, practice with hand-on labs, discover AI/ML, build practical shills and paticipate in AWS communities.\nThe value of AWS Educate The author started from 0 with no formal certificate or training. Initial question: \u0026ldquo;Is it possible to create something truly meaningfull with free resources ? \u0026ndash;\u0026gt; With AWS Educate, the answer is \u0026ldquo;YES\u0026rdquo; The value of AWS Educate: flexible education program depends on presonal pace, high quality contents, visual teaching and especially hand-on labs. The mistakes you made when doing hand-on labs become your important studying experiences. Digital badges helps you maintains motivation and process process. Kickstart your cloud journey Getting started series in AWS Educate introduces core principles like compute, storage, networking and security. Highlights: steps-by-steps learning with practical labs, visual content - easy to understand. Important tips: dont be affraid when making mistakes that where the real learning begins and you must want to build, to understand not just looking to pass time. Practive career skills Not only AWS Educate teachs technical skills but also helps developing soft skills: Writting CV, preparing for interview Communication skills and critical skills. Set goals and manage work effectively. These habits help the author improve faster in both study and work. Expands studys and community After having a foundation, author uses AWS Skill Builder for higher studying Practice with AWS Free Tier without any costs. Join in AWS Community, forums, meetups to share knowledge and learn from others. CONCLUSION / Personal comments After this blog post, i\u0026rsquo;ve leant that:\nAWS Educate is a great choice for one who just comes to Cloud world. Learning theory combined with practice (hands-on labs) is the fastest way to improve. And remember that not to be scared of making mistakes. Cloud is not only a technique, but also associated with career and community skills. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.1-background/",
	"title": "Background &amp; Motivation",
	"tags": [],
	"description": "",
	"content": "1. Background \u0026amp; Motivation 1.1 Executive Summary Customer Background The customer is FPT University HCMC (Academic Board) under the mentorship of Nguyễn Gia Hưng and potential Traffic Enforcement Agencies. They seek a technological demonstration of how IoT and Cloud Computing can solve real-world problems in traffic monitoring. The current manual alcohol inspection process suffers from a lack of operator verification, data fragmentation, and low public transparency.\nBusiness \u0026amp; Technical Objectives Team SPICA proposes a solution named \u0026ldquo;IoT-Based Alcohol Violation Detection System\u0026rdquo; to modernize this workflow. The core objectives include:\nAccountability: Eliminate unauthorized device usage by enforcing Biometric Authentication (Fingerprint) for every session. Transparency: Empower citizens to verify their own violation records via a secure Public Web Portal. Operational Excellence: Replace manual paperwork with an automated, immutable Serverless Cloud Database. Key Use Cases Secure Device Activation: Field officers must scan their fingerprint on the ESP32 Edge Device. The system authenticates against a central DynamoDB pool via AWS IoT Core before enabling the sensors. Multi-Sensor Data Collection: The device captures Alcohol Concentration (MQ-3) and Health Metrics (Heart Rate/SpO2 via MAX30102) simultaneously to ensure the subject\u0026rsquo;s safety during testing. Real-Time Violation Logging: Violation data is encrypted and synced instantly to AWS, accessible via a Dashboard for admins and a Lookup Portal for citizens. 1.2 Project Success Criteria To be considered successful, the system must meet the following quantitative metrics:\nMetric Target Notes Authentication Latency \u0026lt; 2 seconds Round-trip time from Fingerprint Scan $\\to$ Cloud Auth $\\to$ Device Unlock. Data Integrity 99.9% Zero loss of violation records during network stability tests. Security Compliance 100% All Infrastructure-as-Code (Terraform) must pass tfsec scans in the CI/CD pipeline. Deployment Automation Fully Automated Backend deploys via Terraform + GitHub Actions; Frontend deploys via AWS Amplify. Cost Efficiency \u0026lt;$15 / month Operational costs on AWS for the pilot phase. 1.3 Assumptions \u0026amp; Constraints Hardware \u0026amp; Connectivity Device: The team has procured the ESP32 WROOM, AS608 (Fingerprint), MQ-3 (Alcohol), and MAX30102 (Pulse Oximeter) sensors. Network: The Edge Device is assumed to have access to a stable Wi-Fi network or mobile hotspot (4G) during operation. Technical Environment Cloud Access: Team SPICA has Administrator access to a dedicated AWS account for resource provisioning. Development Stack: Firmware: C++ / PlatformIO. Backend: Python (Lambda) \u0026amp; Terraform (IaC). Frontend: React/Vue.js hosted on S3/Amplify. Scope Limitations Legal Admissibility: This project is a technical Proof of Concept (PoC). The sensor readings are for demonstration purposes and are not legally binding in a real court of law without further industrial calibration. Physical Housing: The prototype will use a temporary 3D-printed or acrylic case, not an industrial IP67-rated enclosure. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Trần Quốc Dinh\nPhone Number: 0868495138\nEmail: nguyensoi0966622100@gmail.com\nUniversity: FPT University HCM\nMajor: Software Engineering\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to 12/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction to Automated Remediation Automated Remediation is the use of software and logical rules to detect and fix infrastructure issues without human intervention. They are critical components for building \u0026ldquo;self-healing\u0026rdquo; systems that minimize service downtime. Computing resources running in production may encounter unexpected issues (such as memory overflow, application crashes). Through the combination of Amazon CloudWatch (monitoring) and AWS Systems Manager (execution), the system can automatically respond to these issues immediately instead of waiting for engineers to handle them manually. Workshop Overview In this workshop, you will deploy a completely automated monitoring and issue remediation process.\nWeb-Server-Test is an EC2 Instance resource that acts as a test application server. A CloudWatch Agent has been installed and configured within this instance to collect memory (RAM) metrics – a metric not monitored by default by AWS. You will use the stress tool to simulate a memory overflow attack, causing the server to become unresponsive. EventBridge \u0026amp; Systems Manager simulate an automated operations team. A Rule is configured to listen for alerts from CloudWatch. When memory exceeds the safe threshold, the system will automatically trigger a restart command (Reboot) on the instance through Systems Manager Automation. This mechanism simulates rapid service recovery in real-world environments. In this workshop, we perform the Reboot action to see results immediately, but for production workloads, you can configure more complex procedures such as dumping RAM for error analysis before restarting or replacing instances with Auto Scaling. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Project Overview This worklog documents a 12-week learning journey (September - November 2025) focused on mastering AWS Cloud Computing through hands-on development of an IoT Smart Device Management System. The project serves as a practical vehicle to learn and apply core AWS services, cloud architecture principles, and modern DevOps practices.\nLearning Objectives The primary goal was to gain comprehensive understanding of AWS Cloud Computing fundamentals and core services through hands-on practice:\nCore AWS Services:\nCompute: EC2, Lambda (serverless functions) Storage: S3 (object storage), EBS, CloudFront (CDN) Database: DynamoDB (NoSQL), RDS concepts Networking: VPC, Security Groups, Route 53 Security \u0026amp; Identity: IAM (users, roles, policies), WAF, Shield Monitoring \u0026amp; Management: CloudWatch (metrics, logs, alarms) IoT \u0026amp; Integration: IoT Core, API Gateway, EventBridge Developer Tools: CodePipeline, CodeBuild, Amplify Cloud Architecture Principles:\nInfrastructure as Code (Terraform) for automated provisioning Serverless architecture patterns and best practices Security-first design with least privilege access Cost optimization strategies for cloud resources High availability \u0026amp; scalability design patterns AWS Well-Architected Framework implementation Development Timeline The project followed an agile methodology with weekly sprints, progressing from foundational AWS knowledge through to production-ready deployment:\nWeek 1-7: Foundation \u0026amp; Planning Phase - AWS fundamentals, architecture design, and project planning\nWeek 8: Hardware \u0026amp; IoT Integration - Core pipeline development, sensor integration, AWS IoT Core setup\nWeek 9: Authentication \u0026amp; API Development - Hybrid authentication system, Lambda functions, API Gateway configuration\nWeek 10: Frontend Development \u0026amp; Deployment - Web interface, S3/CloudFront deployment, end-to-end testing\nWeek 11: Infrastructure as Code \u0026amp; CI/CD - Terraform implementation, automated pipelines, security hardening (WAF, monitoring)\nWeek 12: Testing \u0026amp; Documentation - System optimization, final testing, documentation, and project delivery\nKey Learning Outcomes ✅ Hands-on experience with 10+ core AWS services ✅ Serverless architecture mastery - Lambda, API Gateway, DynamoDB ✅ IoT data pipeline implementation with AWS IoT Core and rules engine ✅ Cloud security implementation - IAM policies, WAF rules, encryption ✅ Infrastructure as Code proficiency - Terraform for AWS resource management ✅ CI/CD automation skills - CodePipeline, Amplify deployment workflows ✅ Cloud monitoring \u0026amp; observability - CloudWatch dashboards, alarms, and logs ✅ Cost-aware architecture - Serverless computing and pay-per-use services\nTechnologies Used Cloud Services: AWS IoT Core, Lambda, API Gateway, DynamoDB, S3, CloudFront, CloudWatch, WAF, Shield\nInfrastructure: Terraform, AWS CodePipeline, AWS Amplify\nHardware: ESP32, MQ-3 Sensor, MAX30102 Sensor, AS608 Fingerprint Module\nFrontend: HTML5, CSS3, JavaScript (Vanilla)\nDevelopment: Git, VS Code, AWS CLI\nThis worklog provides detailed weekly documentation of the AWS learning journey, including hands-on exercises, challenges encountered, AWS services explored, and practical skills gained throughout the 12-week cloud computing program.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic Cloud computing and AWS service Learn basic Linux Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Get acquainted with FCJ members\n- Study Module 01-01: What is Cloud Computing? 09/08/2025 09/08/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ 2 - Study Module 01-02: What Makes AWS Different?\n- Understand AWS Regions, Availability Zones, core services (EC2, S3, RDS). 09/09/2025 09/09/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ 3 - Study Module 01-03: How to Start Your Cloud Journey.\n- Learn about AWS Free Tier, AWS Console, and AWS CLI. 09/10/2025 09/10/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ 4 - Do Lab 01-01: Create an AWS account.\n- Configure billing settings, check Free Tier status. 09/11/2025 09/11/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1 5 - Do Lab 01-02: Setup with Virtual MFA Device\n- Learn what MFA is and why it\u0026rsquo;s important. 09/12/2025 09/12/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ 6 - Do Lab 01-03: Create admin group and admin user.\n- Explain the difference between the root account and IAM users 09/13/2025 09/13/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ 7 - Write Worklog Week 1\n- Schedules tasks for week 2 - Start brainstorming ideas for the Project Proposal 09/14/2025 09/14/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=1/ Week 1 Achievements: Got acquainted with FCJ members and understood team workflow.\nCompleted theoretical modules:\nModule 01-01: Understood the basic concept of Cloud Computing. Module 01-02: Learned what makes AWS unique compared to other cloud providers. Module 01-03: Understood how to start the AWS Cloud Journey. Explored AWS Free Tier, AWS Console, and AWS CLI.\nSuccessfully created an AWS Free Tier account and configured billing settings.\nSet up MFA (Multi-Factor Authentication) for the root account.\nCreated an Admin IAM group and an Admin IAM user for daily work.\nPracticed differentiating between Root User and IAM User, and learned best practices for account security.\nCompleted Worklog Week 1 and started brainstorming ideas for the project proposal.\nWeek 1 Reflections: Week 1 Objectives: Tasks to be carried out this week: Week 1 Achievements: Week 1 Reflections: "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.2-architecture/",
	"title": "Solution Architecture",
	"tags": [],
	"description": "",
	"content": "2. Solution Architecture 2.1 High-Level Architecture Diagram The solution leverages a Cloud-Native Serverless Architecture ensuring high scalability, low maintenance, and cost-efficiency. The system connects Edge IoT devices to a centralized AWS backend, protected by comprehensive security layers.\nCore Architectural Layers:\nEdge Layer: ESP32 microcontrollers interacting with biometric and environmental sensors. Ingestion \u0026amp; Compute Layer: AWS IoT Core for secure messaging and AWS Lambda for serverless business logic. Storage Layer: Amazon DynamoDB for fast, NoSQL data storage of officer registries and violation logs. Security \u0026amp; Delivery Layer: AWS WAF protecting Amplify, and API Gateway for secure backend access. DevOps Layer: Automated CI/CD using Terraform \u0026amp; GitHub Actions (Backend) and AWS Amplify (Frontend with built-in CloudFront CDN). 2.2 Technology Stack The system utilizes the following AWS Services and Hardware components:\nCategory Service / Component Purpose IoT \u0026amp; Ingestion AWS IoT Core Secure MQTT Broker (TLS 1.2) for device communication. Compute AWS Lambda (Python) Serverless functions: Authorize, ProcessViolation, GetDashboard, SearchByCCCD. Database Amazon DynamoDB Storage for DeviceOfficerMap_Pool and ViolationsDB (with Global Secondary Indexes). API Layer Amazon API Gateway Exposes secure REST API endpoints to the frontend. Security AWS WAF Protects Amplify hosting from web exploits. Frontend AWS Amplify Hosting (with built-in CloudFront CDN), CI/CD, and integration for the React/Vue SPA. Backend DevOps Terraform + GitHub Actions Infrastructure as Code deployment and CI/CD automation. Monitoring Amazon CloudWatch System logging, metrics, and error alarming. Edge Hardware Components Controller: ESP32 (Wi-Fi/Bluetooth enabled). Sensors: MQ-3: Alcohol Concentration detection. MAX30102: Heart Rate \u0026amp; SpO2 monitoring (Health safety). AS608: Optical Fingerprint Sensor (Biometric Auth). Interface: 4x4 Matrix Keypad and LCD 1602 Display. 2.3 Main Processing Flows A. Authentication Flow (Hybrid) Scan: Officer places finger on the AS608 sensor. Request: ESP32 sends the encrypted SlotID to AWS IoT Core via topic auth/request. Verify: IoT Core triggers the AuthorizeFunction Lambda. Query: Lambda checks the DeviceOfficerMap_Pool table in DynamoDB. Response: System returns an unlock or deny command. The device activates the MQ-3 sensor only upon success. B. Violation Recording Flow Measure: Once unlocked, the device continuously reads MQ-3 sensor data. Detect: If Alcohol Level \u0026gt; Threshold, the device locks and prompts for Citizen ID (CCCD). Input: Officer enters the citizen\u0026rsquo;s CCCD via the Keypad. Upload: Device constructs a JSON payload containing OfficerID, AlcoholLevel, Timestamp, and CCCD, sending it to violations/new. Process: IoT Core triggers ProcessViolationFunction to validate and write the record to ViolationsDB. C. Public Lookup Flow Search: Citizen enters their National ID (CCCD) on the Web Portal. API Call: The frontend requests GET /violations?cccd=... via API Gateway. Fetch: SearchByCCCDFunction queries DynamoDB GSIs. Display: Results are returned and displayed on the dashboard in \u0026lt; 1 second. 2.4 Security Considerations Network Security: All API endpoints are protected by AWS WAF (Web Application Firewall) to block SQL Injection and XSS attacks. Data Encryption: In-Transit: TLS 1.2 for MQTT and HTTPS for API calls. At-Rest: DynamoDB tables are encrypted using AWS KMS. Access Control: IAM Roles: Implementation of \u0026ldquo;Least Privilege\u0026rdquo; for all Lambda execution roles. Device Identity: X.509 Certificates unique to each ESP32 device. Privacy: Sensitive PII (Citizen ID) is handled securely with strict read access policies. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Summary Report: \u0026ldquo;Data Science on AWS Workshop\u0026rdquo; Event Information Date: October 18, 2025 Time: 9:30 - 11:45 AM Venue: Hall A - FPTU HCMC Host: Doan Nguyen Thanh Hoa - CF Lecturer, FPT University HCMC Event Objectives Provide foundational knowledge about Machine Learning and AI Introduce AWS AI/ML ecosystem and services Share practical approaches for data science projects Guide students on building ML solutions using AWS cloud platform Speakers Van Hoang Kha – Cloud Solutions Architect, AWS User Group Leaders Bach Doan Vuong – Cloud DevOps Engineer, AWS Community Builder Key Highlights Machine Learning Fundamentals Definition: Machine Learning (ML) is a field of AI that enables computers to \u0026ldquo;learn\u0026rdquo; from data to perform tasks without explicit programming.\nThree main types:\nSupervised Learning: Learning from labeled data (e.g., spam email classification) Unsupervised Learning: Finding patterns in unlabeled data (e.g., customer segmentation) Reinforcement Learning: Learning through trial and error by interacting with environment (e.g., game AI, autonomous vehicles) Machine Learning Project Lifecycle The standard lifecycle of any Data Science project includes 4 main phases:\nProblem Definition: Transform business problems into machine learning problems Data Processing: Data collection, cleaning, and analysis (often takes the most time) Model Building: Feature Engineering: Create the best features for the model Training \u0026amp; Tuning: Train and fine-tune the model Evaluation: Assess model accuracy Deployment \u0026amp; Operations (MLOps): Deploy model to production, continuous monitoring, and retraining when needed AWS AI/ML Ecosystem AWS provides a comprehensive 3-tier toolkit serving all types of users:\nTier 1: AI Services (Pre-built AI Services - API Usage) Ready-to-use \u0026ldquo;intelligent\u0026rdquo; services you can integrate directly into applications without ML expertise:\nLanguage \u0026amp; Audio Processing:\nAmazon Comprehend: \u0026ldquo;Understanding\u0026rdquo; text (sentiment analysis, entity extraction) Amazon Translate: \u0026ldquo;Translating\u0026rdquo; text between languages Amazon Textract: \u0026ldquo;Reading\u0026rdquo; and extracting text/data from documents, images (intelligent OCR) Amazon Polly: \u0026ldquo;Speaking\u0026rdquo; (text-to-speech with natural voice) Amazon Transcribe: \u0026ldquo;Listening\u0026rdquo; (speech-to-text conversion) Amazon Lex: \u0026ldquo;Brain\u0026rdquo; for building conversational chatbots and voice bots (Alexa technology) Computer Vision:\nAmazon Rekognition: \u0026ldquo;Seeing\u0026rdquo; and analyzing images/videos (object detection, facial recognition) Personalization:\nAmazon Personalize: Building powerful recommendation engines (Amazon.com technology) Tier 2: ML Services (Machine Learning Platform)\nAmazon SageMaker: Comprehensive integrated platform providing tools for every step in the ML workflow, from data preparation to training, deployment, and model monitoring Tier 3: ML Frameworks \u0026amp; Infrastructure\nFull support: Provides powerful servers (CPU, GPU, AWS specialized chips) and supports all popular frameworks Main frameworks: TensorFlow (powerful, comprehensive), PyTorch (flexible, intuitive) Maximum flexibility: Allows bringing your own custom environment to AWS through \u0026ldquo;Bring Your Own Container\u0026rdquo; Key Takeaways Core Mindset \u0026amp; Practical Advice Most important mindset:\nThink like a Cloud Engineer, Not only AI Engineer: To succeed, you need not only to build accurate models but also know how to deploy, scale, optimize costs, and secure them on cloud platforms Data Sources for Individuals Public datasets:\nKaggle, Hugging Face Hub, UCI Repository are the best places to start Self-generated data:\nUse Web Scraping techniques, APIs, or use AI itself to create Synthetic Data AWS ML Strategy Three-tier approach:\nStart simple: Use AI Services for quick wins and proof of concepts Scale intelligently: Move to SageMaker for custom ML workflows Optimize deeply: Leverage infrastructure tier for maximum performance and cost efficiency Implementation Best Practices Data quality first: Clean, relevant data is more important than complex algorithms Start with business problems: Don\u0026rsquo;t build ML for the sake of technology Iterate quickly: Use AWS managed services to focus on business logic, not infrastructure Monitor continuously: ML models degrade over time and need ongoing attention Applying to Work Start with AI Services: Use Amazon Rekognition, Comprehend, or Translate for quick wins in current projects Explore SageMaker: Begin with SageMaker Studio for data exploration and model experimentation Practice data collection: Use web scraping and public datasets to build personal ML projects Learn MLOps: Understand the full ML lifecycle from development to production deployment Build cloud-native: Design ML solutions with scalability, cost optimization, and security in mind Join AWS community: Connect with AWS User Groups and Community Builders for knowledge sharing Event Experience Attending the \u0026ldquo;Data Science on AWS\u0026rdquo; workshop at FPT University was an enlightening experience that provided comprehensive insights into machine learning and AWS cloud services. Key experiences included:\nLearning from AWS experts Van Hoang Kha and Bach Doan Vuong shared extensive knowledge about AWS AI/ML ecosystem and real-world implementation strategies. Through practical examples, I gained deeper understanding of the 3-tier AWS ML architecture and how different services complement each other. Understanding ML fundamentals Learned the three main types of machine learning: supervised, unsupervised, and reinforcement learning with clear examples. Understood the complete ML project lifecycle from problem definition to deployment and ongoing operations. Discovered the importance of data quality and feature engineering in building successful ML models. Exploring AWS AI services Got hands-on exposure to pre-built AI services like Amazon Comprehend, Rekognition, and Translate that can be integrated immediately. Learned about Amazon SageMaker as a comprehensive platform for custom ML workflows and model management. Understood the infrastructure layer supporting popular frameworks like TensorFlow and PyTorch. Developing cloud-native mindset The concept of \u0026ldquo;Think like a Cloud Engineer, Not only AI Engineer\u0026rdquo; was particularly valuable, emphasizing the importance of deployment, scaling, and cost optimization. Learned about MLOps practices and the need for continuous monitoring and model retraining. Understanding the balance between technical capabilities and business requirements. Practical guidance for data acquisition Discovered valuable public datasets on Kaggle, Hugging Face Hub, and UCI Repository for learning and experimentation. Learned about web scraping techniques and using AI to generate synthetic data for training purposes. Understood the importance of data preparation and cleaning as often the most time-consuming part of ML projects. Networking and community building Connected with AWS community builders and learned about ongoing support through user groups. Exchanged ideas with fellow students and professionals interested in data science and cloud computing. Gained insights into career paths in cloud engineering and data science fields. Overall, this workshop not only provided technical knowledge about AWS ML services but also helped me understand the complete journey from business problems to deployed ML solutions, emphasizing the importance of cloud-native thinking in modern data science projects.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Learn about AWS Global Infrastructure and AWS service management tools. Understand cost optimization strategies on AWS and how to work with AWS Support. Learn about AWS Virtual Private Cloud and advanced features (Module 02-01 → 02-03). Practice creating and managing budgets, working with AWS Support, and how to create and adjust a VPC Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Study Module 01-04: AWS Global Infrastructure\n- Study Module 01-05: AWS Management Tools 09/15/2025 09/15/2025 Module 01-05 - Công Cụ Quản Lý AWS Services 2 - Study Module 01-06: AWS Cost Optimization and AWS Support 09/16/2025 09/16/2025 Module 01-06 - Tối Ưu Hóa Chi Phí Trên AWS và Làm Việc Với AWS Support 3 - Do Lab 01-Lab07-01 → 01-Lab07-06: Create and Manage Budgets 09/17/2025 09/17/2025 Module 01-07 - Thực Hành và Nghiên Cứu Bổ Sung 4 - Do Lab 01-Lab09-01 → 01-Lab09-04: AWS Support 09/18/2025 09/18/2025 Module 01-Lab07-01 - Create Budget by Template 5 - Study Module 02-01 → 02-03 (theory) 09/19/2025 09/19/2025 Module 02-01 - AWS Virtual Private Cloud 6 - Do Lab 02-03-03.1 → 02-03-03.5Study Module 02-01 → 02-03 (theory) 09/20/2025 09/20/2025 Module 02-Lab03-01 - Start with Amazon VPC and AWS VPN Site-to-Site ( Introduction ) 7 - Write Worklog Week 2 report: Budgets setup, cost optimization insights and translate 2d blog 09/21/2025 09/21/2025 Week 2 Achievements: Completed theoretical modules:\nModule 01-04: Understood AWS Global Infrastructure, regions and availability zones. Module 01-05: Learned about AWS Management Tools (Console, CLI, CloudFormation, CloudWatch, etc.). Module 01-06: Understood AWS Cost Optimization practices and AWS Support. Module 02-01 → 02-03: Gained knowledge of advanced AWS VPC. Completed lab exercises:\n01-Lab07-01 → 01-Lab07-06: Successfully created and managed budgets. 01-Lab09-01 → 01-Lab09-04: Worked with AWS Support and explored Trusted Advisor. 02-03-03.1 → 02-03-03.5: Completed lab exercises related to VPC. Deliveredables:\nSubmitted Worklog Week 2 with report on cost optimization and budget setup. Translated 2d BLog Week 2 Reflections: Week 2 Objectives: Tasks to be carried out this week: Week 2 Achievements: Week 2 Reflections: "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "HOW TO SAVE MONEY ON CLOUD: 10 SIMPLE TIPS FOR SCHOOLS This blog post shows schools and universities how to spend less money when using Amazon Web Services (AWS). The writer talks about why it is important to watch your spending and gives 10 easy tips. These tips help schools use cloud services well while not spending too much money. The main idea is to use only what you need, not more than you need.\nWhy Save Money on Cloud In the past, schools had to buy computers and equipment for the highest number of users they might have. Cloud services let you use only what you need right now and not buy extra things. Many schools forget this when they first start using cloud services. Schools need to watch their cloud spending carefully to get the best value for their money. Simple Money-Saving Tips (1-5) 1. Set Up Spending Alerts\nUse AWS Budgets to get warnings when you spend too much money This helps you know when your bills are getting high Very helpful for free services so you don\u0026rsquo;t get surprised when they are not free anymore 2. Use the Right Size of Resources\nFind computers (EC2), databases (RDS), or storage (EBS) that are too big for what you need Think about using smaller sizes or different types that cost less Use AWS tools to get suggestions on better sizes Keep checking this because your needs change over time 3. Use Spot Instances\nFor work that can wait or stop and start again, use EC2 Spot Instances These can save up to 90% of money compared to normal prices Good for research work that doesn\u0026rsquo;t need to run all the time 4. Turn Off Computers When Not Needed\nSet up rules to turn off EC2 computers during nights and weekends Use AWS tools to do this automatically This saves money for things you don\u0026rsquo;t need running 24 hours a day 5. Use Smart Storage Rules\nMake S3 storage cheaper by moving old files to cheaper storage Use Glacier for files you don\u0026rsquo;t need often Use AWS tools to see which files you can move More Money-Saving Tips (6-10) 6. Check Your Backup Rules\nLook at how long you keep backup copies of your data Important work might need to keep backups for many years Test work doesn\u0026rsquo;t need backups for so long 7. Use Smart Storage That Changes Automatically\nAmazon S3 Intelligent-Tiering moves your files to cheaper storage when you don\u0026rsquo;t use them much This happens automatically so you don\u0026rsquo;t have to think about it 8. Delete Old Unused Files\nFind and delete storage that is not connected to anything Delete old snapshots and incomplete uploads Use AWS tools to manage this automatically 9. Put Multiple Accounts Together\nIf your school has many AWS accounts, put them under fewer main accounts This can help you get discounts and save money on data transfer Consider using CloudFront to save money on internet traffic 10. Use Savings Plans and Reserved Instances\nIf you use EC2, Lambda, SageMaker, or RDS regularly, buy them for 1-3 years This can save up to 72% compared to normal prices Make sure you have the right sizes before buying these plans Extra Help and Resources Special Benefits for Schools:\nNo Tax: Many schools don\u0026rsquo;t have to pay tax on AWS services Learning Materials: AWS Skill Builder, AWS videos on YouTube and Twitch, AWS Blogs Getting Help: AWS Community website, support from AWS team if you have business support Ways to Learn More:\nAWS workshops about saving money AWS team can visit your school to teach Special support person if you have enterprise support CONCLUSION / What I Learned After reading this blog, I learned that:\nSchools need to think differently about using cloud compared to buying their own computers These 10 tips give schools a good plan to control their cloud costs Watching your spending and using the right size resources is very important AWS has many tools and people to help schools save money Schools have special benefits like no tax and education discounts that they should use "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.2-prerequiste/",
	"title": "Preparation Steps",
	"tags": [],
	"description": "",
	"content": "IAM Permissions Attach the following IAM permission policy to your AWS user account to deploy and clean up resources in this workshop.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;WorkshopPermissions\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:TerminateInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:RebootInstances\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;cloudwatch:PutMetricData\u0026#34;,\r\u0026#34;cloudwatch:GetMetricStatistics\u0026#34;,\r\u0026#34;cloudwatch:ListMetrics\u0026#34;,\r\u0026#34;cloudwatch:PutMetricAlarm\u0026#34;,\r\u0026#34;cloudwatch:DeleteAlarms\u0026#34;,\r\u0026#34;cloudwatch:DescribeAlarms\u0026#34;,\r\u0026#34;events:PutRule\u0026#34;,\r\u0026#34;events:PutTargets\u0026#34;,\r\u0026#34;events:DeleteRule\u0026#34;,\r\u0026#34;events:RemoveTargets\u0026#34;,\r\u0026#34;events:DescribeRule\u0026#34;,\r\u0026#34;events:ListRules\u0026#34;,\r\u0026#34;ssm:GetDocument\u0026#34;,\r\u0026#34;ssm:ListDocuments\u0026#34;,\r\u0026#34;ssm:DescribeInstanceInformation\u0026#34;,\r\u0026#34;ssm:GetAutomationExecution\u0026#34;,\r\u0026#34;ssm:StartAutomationExecution\u0026#34;,\r\u0026#34;sns:CreateTopic\u0026#34;,\r\u0026#34;sns:Subscribe\u0026#34;,\r\u0026#34;sns:Publish\u0026#34;,\r\u0026#34;sns:DeleteTopic\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Lab Environment We will build the infrastructure from scratch to understand how to install the Agent and configure permissions (IAM Role).\nBasic Requirements:\nDefault VPC: Ensure that your us-east-1 region has a Default VPC available. If you have already deleted it, create a new VPC with a simple Public Subnet configuration.\nInternet Access: The EC2 Instance in this lab will need Internet connectivity to download the stress package and amazon-cloudwatch-agent.\nCheck Default VPC in Console\nAfter ensuring the permissions and VPC are in place, you are ready to proceed to the implementation phase.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "AWS First Cloud AI Journey IoT-Based Alcohol Violation Detection System Project Team: SPICA\nUniversity: FPT University HCMC\nProject Name: IoT-Based Alcohol Violation Detection System\nDate: 2025-12-05\nPlease navigate through the sections below to view the detailed project plan:\nBackground \u0026amp; Motivation\nContext, objectives, and success criteria.\nSolution Architecture\nTechnical diagrams, stack details, and security.\nActivities \u0026amp; Deliverables\nTimeline, milestones, and path to production.\nCost Breakdown\nEstimated AWS monthly operational costs.\nTeam\nStakeholders and project members.\nResources \u0026amp; Estimates\nEffort estimation and cost contribution.\nAcceptance\nCriteria for project sign-off.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Summary Report: \u0026ldquo;Workshop: Secure Your Applications - AWS Perimeter Protection\u0026rdquo; Event Information Date: Tuesday, November 19th, 2025 Time: Full-day workshop Location: AWS Training Center, Ho Chi Minh City Organizer: AWS Vietnam Event Type: Hands-on Technical Workshop Instructors Mr. Nguyen Gia Hung – Head of Solutions Architects, AWS Vietnam Mr. Julian Ju – Regional Edge Security Specialist, AWS APAC Mr. Kevin Lim – Regional Edge Security Specialist, AWS APAC Event Objectives Understand AWS edge security services and perimeter protection strategies Learn how to protect web applications from common attacks (SQL Injection, XSS, DDoS) Master AWS WAF (Web Application Firewall) configuration and rule management Implement AWS Shield for DDoS protection and resilience Gain hands-on experience with real-world security scenarios Design secure application architectures using AWS edge services Workshop Structure Session 1: Introduction to AWS Edge Security (Morning) Topics Covered:\nOverview of AWS edge security services ecosystem Understanding the shared responsibility model for application security Common web application vulnerabilities (OWASP Top 10) AWS edge security architecture patterns Key Concepts:\nEdge Security: Protecting applications at the network perimeter before threats reach backend infrastructure Defense in Depth: Multi-layered security approach CloudFront Integration: Content delivery with built-in security features Session 2: AWS WAF Deep Dive (Late Morning) AWS WAF Fundamentals:\nWeb Application Firewall architecture and components Rule groups and rule priority WAF managed rules vs custom rules Integration with CloudFront, Application Load Balancer, and API Gateway Threat Protection Mechanisms:\nSQL Injection Prevention\nPattern matching for SQL syntax Request body inspection Query string analysis Cross-Site Scripting (XSS) Protection\nScript tag detection JavaScript injection prevention HTML entity encoding Rate Limiting\nRequest throttling per IP Bot detection and mitigation Geographic restrictions Session 3: Hands-on Lab - AWS WAF Configuration (Afternoon) Lab Objectives: Participants configured AWS WAF to protect a sample web application from various attacks.\nLab Activities:\nPart 1: Initial Setup\nCreated a CloudFront distribution with origin web server Deployed sample vulnerable web application for testing Set up CloudWatch logging for security monitoring Part 2: SQL Injection Protection\nSteps performed:\r1. Created WAF Web ACL (Access Control List)\r2. Added SQL Injection match condition\r3. Configured rule to block suspicious SQL patterns\r4. Tested with simulated SQL injection attacks\r5. Verified blocking behavior in CloudWatch logs Key Configuration:\nRule Priority: High Action: Block Scope: Request body and query strings Patterns: Common SQL keywords (SELECT, UNION, DROP, etc.) Part 3: XSS Protection Implementation\nSteps performed:\r1. Added XSS match condition to Web ACL\r2. Configured script tag detection rules\r3. Set up JavaScript pattern matching\r4. Tested with XSS payloads\r5. Analyzed blocked requests Part 4: Rate Limiting Rules\nSteps performed:\r1. Created rate-based rule (1000 requests per 5 minutes)\r2. Configured IP-based throttling\r3. Simulated high-volume requests\r4. Observed automatic blocking behavior Session 4: AWS Shield for DDoS Protection (Late Afternoon) AWS Shield Overview:\nShield Standard: Automatic protection at no extra cost Shield Advanced: Enhanced DDoS protection with 24/7 support DDoS Attack Types Covered:\nNetwork Layer Attacks (Layer 3/4)\nSYN floods UDP reflection attacks TCP connection exhaustion Application Layer Attacks (Layer 7)\nHTTP floods Slowloris attacks Application-specific exploits Shield Implementation:\nEnabled AWS Shield Advanced for critical resources Configured DDoS Response Team (DRT) access Set up CloudWatch alarms for attack detection Reviewed cost protection policies Hands-on Activities:\nAnalyzed historical DDoS attack patterns Configured automatic attack mitigation Set up real-time attack notifications Reviewed DDoS attack reports and metrics Technical Deep Dives AWS WAF Rule Design Best Practices 1. Layered Protection Strategy\nLayer 1: Managed Rule Groups (AWS Managed Rules)\r- Core Rule Set (CRS)\r- Known Bad Inputs\r- Admin Protection\rLayer 2: Rate-based Rules\r- Geographic rate limiting\r- IP reputation lists\r- Custom rate thresholds\rLayer 3: Custom Business Logic Rules\r- Application-specific patterns\r- Authentication bypass prevention\r- Sensitive data exposure protection 2. Rule Evaluation Order\nCount rules for monitoring (no blocking) Allow rules for trusted sources Block rules for known threats Rate-based rules for volume control Default action (typically Allow) Integration Architecture CloudFront + WAF + Shield Architecture:\nInternet\r↓\rAWS Shield (DDoS Protection)\r↓\rAmazon CloudFront (Edge Locations)\r↓\rAWS WAF (Application Layer Filtering)\r↓\rApplication Load Balancer\r↓\rBackend Application (EC2/ECS/Lambda) Benefits of Edge Protection:\nThreats blocked before reaching infrastructure Reduced backend load and costs Improved application performance Global threat intelligence sharing Monitoring and Incident Response CloudWatch Integration:\nReal-time metrics dashboards Blocked request patterns Geographic attack sources False positive identification Logging Strategy:\nFull request/response logging Centralized log aggregation Automated threat analysis Compliance audit trails Incident Response Workflow:\nAlert triggered by CloudWatch alarm Security team reviews blocked requests Analyze attack patterns and sources Adjust WAF rules if needed Document incident for future reference Real-World Scenarios Discussed Case Study 1: E-commerce Platform Protection Challenge: Online retailer experiencing credential stuffing attacks Solution:\nImplemented rate-based rules per user session Added CAPTCHA challenges for suspicious IPs Configured custom rules for login endpoints Result: 95% reduction in fraudulent login attempts Case Study 2: API Gateway Security Challenge: RESTful API vulnerable to injection attacks Solution:\nDeployed WAF on API Gateway Created custom rules for API-specific threats Implemented request size limits Result: Zero successful injection attacks post-deployment Case Study 3: DDoS Attack Mitigation Challenge: Media website targeted by 300 Gbps DDoS attack Solution:\nAWS Shield Advanced automatic mitigation CloudFront geographic restrictions Emergency runbook activation Result: Application remained available with \u0026lt; 1% performance impact Key Takeaways Technical Skills Acquired AWS WAF Expertise:\n✅ Configured Web ACLs with multiple rule types ✅ Implemented SQL Injection and XSS protection ✅ Set up rate-based rules for bot mitigation ✅ Integrated WAF with CloudFront and ALB ✅ Analyzed security logs and metrics DDoS Protection Knowledge:\n✅ Understood different DDoS attack vectors ✅ Implemented AWS Shield protection layers ✅ Configured automatic attack response ✅ Set up monitoring and alerting systems Security Architecture:\n✅ Designed defense-in-depth strategies ✅ Applied edge security best practices ✅ Implemented zero-trust principles ✅ Optimized cost vs security trade-offs Best Practices Learned 1. Security by Design\nImplement security controls from day one Regular security testing and updates Continuous monitoring and improvement 2. Automation First\nAutomate threat detection and response Use managed rules when possible Implement Infrastructure as Code for consistency 3. Cost Optimization\nStart with Shield Standard (free tier) Use managed rules before custom rules Monitor and optimize rule efficiency 4. Compliance and Governance\nDocument all security configurations Regular audit and compliance reviews Incident response playbooks Practical Applications Immediate Implementation Plans:\nWeek 1: Deploy AWS WAF on development environment Week 2: Configure core rule sets and test thoroughly Week 3: Enable production deployment with monitoring Week 4: Review metrics and optimize rules Skills to Practice:\nRegular WAF rule testing and updates Security log analysis and pattern recognition Incident response procedures Cost monitoring and optimization Personal Reflection This workshop was exceptionally valuable, providing deep technical knowledge about AWS edge security services. The hands-on labs with real attack scenarios made the learning highly practical and engaging.\nMost Valuable Aspects:\nExpert Instruction: Learning from AWS regional specialists (Julian Ju and Kevin Lim) provided insights not available in documentation Hands-on Practice: Configuring WAF rules and testing with real attacks solidified theoretical knowledge Real-world Cases: Case studies demonstrated practical application in production environments Architecture Patterns: Understanding how to integrate multiple security services effectively Challenges Faced:\nRule priority and evaluation order initially confusing Balancing security strictness with false positive prevention Understanding cost implications of different configurations Key Learnings:\nEdge security is critical for modern cloud applications AWS provides powerful tools, but proper configuration is essential Security is an ongoing process, not a one-time setup Integration of multiple services (WAF + Shield + CloudFront) provides comprehensive protection Future Applications: This knowledge is directly applicable to:\nSecuring microservices architectures Protecting API endpoints Implementing compliance requirements (PCI-DSS, SOC 2) Designing resilient, security-first cloud applications Resources and References AWS Documentation:\nAWS WAF Developer Guide AWS Shield Advanced Best Practices CloudFront Security Documentation Well-Architected Framework - Security Pillar Tools and Services Used:\nAWS WAF (Web Application Firewall) AWS Shield (Standard and Advanced) Amazon CloudFront Application Load Balancer AWS CloudWatch AWS Config for compliance Additional Learning Resources:\nAWS Security Hub for centralized security management AWS Firewall Manager for multi-account governance OWASP Top 10 vulnerability guides AWS Security Blog for latest threats and solutions Summary: This workshop provided comprehensive, hands-on training in AWS edge security services, specifically AWS WAF and AWS Shield. The combination of expert instruction from AWS specialists, practical labs with real attack scenarios, and real-world case studies made this an invaluable learning experience. The skills acquired are immediately applicable to securing production cloud applications and designing resilient, security-first architectures.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Learn about Amazon Elastic Compute Cloud (EC2) and its core concepts. Understand instance types, AMI, EBS, Instance Store, User Data, and Meta Data. Practice launching and configuring both Windows and Linux instances. Deploy a sample Node.js CRUD application (AWS User Management) on EC2. Explore EC2 Auto Scaling basics. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Study Module 03-01: Compute VM on AWS 09/22/2025 09/22/2025 Module 03-01 - Compute VM on AWS 2 - Study Module 03-01-01: EC2 Instance Type\n- Study Module 03-01-02: AMI / Backup / Key Pair 09/23/2025 09/23/2025 Module 03-01-01 - Amazon EC2 Instance type 3 - Study Module 03-01-03: Amazon Elastic Block Store\n- Study Module 03-01-04: Instance Store 09/24/2025 09/24/2025 Module 03-01-03 - Amazon Elastic Block Store 4 - Study Module 03-01-05: User Data\n- Study Module 03-01-06: Meta Data 09/25/2025 09/25/2025 Module 03-01-05 - EC2 User Data 5 - Study Module 03-01-07: EC2 Auto Scaling 09/26/2025 09/26/2025 Module 03-01-07 - EC2 Auto Scaling 6 - Do Lab: Launch Windows and Linux EC2 instances, configure Security Groups and Key Pairs 09/27/2025 09/27/2025 AWS Lab Guide + Class Material 7 - Deploy AWS User Management CRUD app on Linux EC2\n- Deploy AWS User Management CRUD app on Windows EC2\n- Write Week 3 Worklog 09/28/2025 09/28/2025 AWS Lab Guide + GitHub Repository Week 3 Achievements: Completed theoretical modules:\nUnderstood EC2 basics and instance lifecycle. Learned about AMI, Backup, Key Pair, EBS, and Instance Store. Explored User Data \u0026amp; Meta Data for automation and instance information. Studied EC2 Auto Scaling for scalability and cost optimization. Completed lab exercises:\nSuccessfully launched Windows and Linux EC2 instances. Configured security groups and key pairs for secure access. Deployed AWS User Management (Node.js CRUD app) on both Linux and Windows instances. Deliverables:\nSubmitted Worklog Week 3. Running demo of AWS User Management accessible through EC2 public DNS. Week 3 Reflections: Practicing with both Windows and Linux EC2 helped me understand differences in deployment and management. I saw how important security groups and key pairs are in controlling access. The Node.js CRUD app deployment gave me real-world experience connecting EC2 instances with MySQL. This week helped me bridge the gap between theory (videos, modules) and practice (lab, deployment). "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.3-activities/",
	"title": "Activities &amp; Deliverables",
	"tags": [],
	"description": "",
	"content": "3. Activities \u0026amp; Deliverables 3.1 Activities and Deliverables Matrix The project is executed over a 12-week timeline (September - November 2025), with Week 1-7 focused on AWS fundamentals and preparation, and Week 8-12 dedicated to hands-on development following Agile methodology.\nProject Phase Timeline Key Activities Deliverables / Milestones Est. Effort I. AWS Fundamentals \u0026amp; Planning Week 1-7 • Learn AWS Core Services\n• Finalize Architecture \u0026amp; DB Schema\n• Setup AWS Account \u0026amp; IAM Roles\n• Initialize Terraform State (S3) • AWS Certification Knowledge\n• Architecture Document (LLD)\n• Terraform Backend Setup\n• Database Schema Design 40 man-days II. Hardware \u0026amp; IoT Integration Week 8 • Wire ESP32 with AS608, MQ-3, MAX30102\n• Implement MQTT Auth Logic\n• Setup AWS IoT Core Pipeline\n• Calibrate Sensors • Flashed ESP32 Device\n• IoT Core Connection Established\n• Sensor Reading Logs 8 man-days III. Authentication \u0026amp; Backend Week 9 • Develop Lambda Functions (Python)\n• Configure API Gateway \u0026amp; Rules Engine\n• Implement Hybrid Auth System • Deployed Serverless Stack\n• Working REST APIs\n• Fingerprint Authentication 8 man-days IV. Frontend Development Week 10 • Build Web Portal (HTML/CSS/JS)\n• Integrate APIs\n• Setup AWS Amplify Hosting • Public Website URL\n• Dashboard UI\n• Citizen Lookup Feature 8 man-days V. Infrastructure as Code \u0026amp; CI/CD Week 11 • Implement Terraform for IaC\n• Setup GitHub Actions workflow\n• Configure AWS WAF Rules\n• Security Hardening • Automated CI/CD Pipeline\n• WAF Protection Active\n• CloudWatch Monitoring 8 man-days VI. Testing \u0026amp; Documentation Week 12 • End-to-End System Testing\n• Final Demo to Stakeholders\n• Documentation \u0026amp; Knowledge Transfer • Final Project Report\n• Source Code Repository\n• User Manual 8 man-days 3.2 Out of Scope The following items are explicitly excluded from this Proof of Concept (PoC) to ensure focused delivery within the 12-week timeframe:\nMobile Application: No native iOS or Android apps will be developed; the mobile-responsive Web Portal will serve mobile users. Industrial Hardware Design: The prototype will use breadboards or a basic 3D-printed case, not an IP67-rated industrial enclosure. Legal Admissibility: The alcohol sensor readings are for technical demonstration only and are not certified for legal enforcement in court. Legacy Integration: No integration with existing on-premise government SQL servers or legacy police databases. 3.3 Path to Production The current system represents a Technical Proof of Concept (PoC). To transition this solution to a Production-ready environment for real-world deployment, the following steps are required:\nHigh Availability: Enable DynamoDB Global Tables for multi-region redundancy. Deploy API Gateway across multiple Availability Zones (AZs). Offline Resilience: Implement AWS IoT Greengrass on a local gateway to buffer violation data when network connectivity is lost. Security Hardening: Migrate hardcoded configuration secrets to AWS Secrets Manager. Conduct rigorous 3rd-party Penetration Testing. Operational Excellence: Set up advanced CloudWatch Anomaly Detection alerts. Establish a formal Incident Response Plan. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.3-iam/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Create IAM Role First, we need to grant permissions to the EC2 Instance so it can send data to CloudWatch and allow Systems Manager to control it (for reboot).\nSteps Access IAM Console Open AWS Management Console and select IAM service. Create a new Role Select Roles from the left menu. Click Create role. Configure Trusted Entity Type Under Trusted entity type, select AWS service. Under Service or use case, select EC2. Click Next. Attach Permissions Policies In the Permissions policies search box, find and select (check the box) 2 permissions: CloudWatchAgentServerPolicy (To push logs/metrics) AmazonSSMManagedInstanceCore (To connect Session Manager and execute Automation) Click Next. Name the Role Set the Role name as: EC2-Monitor-AutoFix-Role Click Create role. You have successfully created an IAM Role to grant permissions to the EC2 instance.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "This section lists and introduces the blogs I have translated during my internship. Each blog covers important AWS and cloud computing topics, providing valuable insights and practical knowledge.\nBlog 1 - From Curious to Building Real-Life AWS Projects: My Cloud Journey with AWS Educate Original Topic: Personal journey and learning path with AWS Educate\nThis blog shares an inspiring story of transformation from a complete beginner with no cloud computing background to successfully building real-world AWS projects. The author, Nikhil Nareddula, demonstrates how AWS Educate provides a comprehensive, flexible, and free learning platform for anyone starting their cloud journey.\nKey Topics Covered:\nAWS Educate Value Proposition: Self-paced learning with high-quality content, visual teaching methods, and hands-on labs Getting Started Journey: Step-by-step progression through core AWS concepts including compute, storage, networking, and security Learning by Doing: Emphasis on practical labs where mistakes become valuable learning experiences Career Development: Beyond technical skills, the program includes CV writing, interview preparation, and communication skills Community Engagement: Utilizing AWS Skill Builder, AWS Free Tier, and joining AWS communities for continuous learning Translation Insights: This blog is particularly valuable for students and beginners who feel overwhelmed by cloud computing. It demonstrates that with free resources like AWS Educate, anyone can start learning cloud technologies without financial barriers. The digital badges system mentioned helps maintain motivation and track progress throughout the learning journey.\nPersonal Takeaway: AWS Educate is an excellent starting point for newcomers to the cloud world, offering structured learning paths combined with practical experience.\nBlog 2 - How to Save Money on Cloud: 10 Simple Tips for Schools Original Topic: AWS cost optimization strategies for educational institutions\nThis practical blog provides schools and universities with actionable strategies to optimize their AWS spending while maintaining service quality. It addresses the common challenge where educational institutions, new to cloud services, often forget the \u0026ldquo;pay-as-you-go\u0026rdquo; principle and overspend on resources.\n10 Cost-Saving Tips Covered:\n1. Set Up Spending Alerts\nImplement AWS Budgets for proactive cost monitoring Receive warnings before exceeding budget thresholds Prevent surprise bills when free tier limits expire 2. Use the Right Size of Resources\nRight-size EC2 instances, RDS databases, and EBS volumes Leverage AWS optimization tools for recommendations Continuously review and adjust as needs change 3. Use Spot Instances\nSave up to 90% on compute costs for interruptible workloads Ideal for research projects and batch processing Perfect for non-critical, flexible computing tasks 4. Turn Off Computers When Not Needed\nAutomate EC2 instance scheduling for off-hours shutdown Implement weeknight and weekend shutdown policies Eliminate 24/7 costs for development and testing environments 5. Use Smart Storage Rules\nImplement S3 Lifecycle policies for automatic data tiering Archive infrequently accessed data to S3 Glacier Optimize storage costs based on access patterns Additional Tips (6-10):\nReserved Instances for predictable workloads Serverless architectures to eliminate idle costs Regular cleanup of unused resources AWS Cost Explorer for spending analysis Educational credits and AWS Educate benefits Translation Insights: This blog is simplified to be easily understood by non-technical administrators and decision-makers in educational institutions. The practical, numbered format makes it easy to implement recommendations step-by-step.\nPersonal Takeaway: Cost optimization is not a one-time task but an ongoing practice. Educational institutions can significantly reduce cloud spending by implementing these simple yet effective strategies, allowing them to allocate more budget to actual learning and research activities.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Complete hands-on AWS labs to gain practical experience with core AWS services. Explore various AWS services including Cloud9, S3, and RDS. Translate AWS blog posts to practice technical writing and understanding of AWS use cases. Build comprehensive knowledge of AWS cloud development, storage, and database services. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Complete Lab: Cloud Development with AWS Cloud9\n- Set up cloud-based IDE environment 29/09/2025 29/09/2025 AWS Educate Lab Guide + AWS Cloud9 Documentation 2 - Complete Lab: Static Website Hosting with Amazon S3\n- Deploy and configure static website 30/09/2025 30/09/2025 AWS Educate Lab Guide + Amazon S3 Documentation 3 - Complete Lab: Database Essentials with Amazon RDS\n- Set up and manage relational database 01/10/2025 01/10/2025 AWS Educate Lab Guide + Amazon RDS Documentation 4 - Practice AWS CLI commands and automation\n- Review and document lab learnings 02/10/2025 02/10/2025 AWS CLI Documentation + Lab Notes 5 - Translate Blog: Cultural shift to cloud savings (DWP FinOps journey)\n- Technical writing practice 03/10/2025 03/10/2025 AWS Blog + Translation Guidelines 6 - Translate Blog: University of Sheffield research acceleration\n- Practice technical documentation 04/10/2025 04/10/2025 AWS Blog + Documentation Guidelines 7 - Translate Blog: Amazon Connect integration\n- Write Week 4 Worklog and self-reflection 05/10/2025 05/10/2025 AWS Blog + Worklog Template Week 4 Achievements: Completed practical AWS labs:\nAWS Cloud9: Set up cloud-based development environment, practiced coding in the cloud. Amazon S3: Deployed static websites, configured buckets, managed permissions and hosting. Amazon RDS: Created and managed relational databases, learned backup and security practices. Completed blog translations:\nDWP FinOps Journey: Translated comprehensive case study about UK government\u0026rsquo;s cloud cost optimization. University Research: Translated article about accelerating secure research with AWS services. Amazon Connect Integration: Translated technical article about Microsoft Teams integration. Technical skills development:\nHands-on experience with cloud development environments. Understanding of static website hosting and content delivery. Database management and relational database concepts. AWS CLI automation and command-line operations. Technical translation and documentation skills. Week 4 Reflections: The combination of hands-on labs and blog translation provided both practical and theoretical understanding. AWS Cloud9 showed me the power of cloud-based development environments for collaboration. S3 static hosting demonstrated how simple yet powerful AWS storage services can be for web deployment. RDS labs gave me confidence in managing enterprise-grade databases in the cloud. AWS CLI practice enhanced my automation skills and command-line proficiency for cloud operations. Blog translations helped me understand real-world AWS implementations and improved my technical writing skills. View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel. \u0026hellip; "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.4-cost/",
	"title": "Cost Breakdown",
	"tags": [],
	"description": "",
	"content": "4. Expected Cost Breakdown 4.1 AWS Operational Costs (Monthly) The following cost estimation is based on a Pilot Phase workload assumption of approximately 10,000 violation records/month (equivalent to ~330 inspections/day) in the ap-southeast-1 (Singapore) or us-east-1 (N. Virginia) region.\nService Estimated Cost (USD) Notes AWS WAF $6.00 1 Web ACL + 1 Rule Group (Essential for API security). Amazon CloudWatch $2.80 ~5GB of Log ingestion \u0026amp; storage + 3 Alarm metrics. AWS Amplify $2.72 Hosting (with built-in CloudFront CDN), Build minutes (100 mins), and Data Transfer (20GB). AWS IoT Core $1.00 Connectivity \u0026amp; Messaging costs for ~10,000 MQTT messages. AWS Lambda $0.22 Compute cost for ~25,000 invocations (Includes Free Tier buffer). Amazon API Gateway $0.07 REST API calls (~20,000 requests). Amazon DynamoDB $0.02 On-demand Read/Write capacity units (Highly efficient). GitHub Actions $0.00 Free for public repositories. TOTAL ~$12.83 Per Month Note: Actual costs may vary slightly based on data transfer rates and region selection. This estimate does not account for the AWS Free Tier, which may reduce the cost to \u0026lt;$10/month for the first 12 months. Amplify hosting includes built-in CloudFront CDN distribution at no additional cost.\n4.2 Hardware Costs (One-Time) This is the material cost to build one unit of the Edge Device Prototype.\nComponent Model Est. Price (USD) Purpose Microcontroller ESP32 WROOM-32 $5.00 Main processing unit with Wi-Fi/BLE. Alcohol Sensor MQ-3 Module $3.00 Detects alcohol concentration in breath. Biometric Sensor AS608 Optical $12.00 Fingerprint scanning and verification. Health Sensor MAX30102 $3.00 Measures Heart Rate and SpO2. Display \u0026amp; UI LCD 1602 + Keypad $2.00 User interaction interface. Power \u0026amp; Misc Battery, Wires, Case $3.00 Consumables and 3D printed casing. TOTAL ~$25.00 Per Device 4.3 Cost Optimization Strategy To ensure the project remains within budget during the scaling phase, Team SPICA will implement:\nDynamoDB On-Demand: Eliminates costs for idle time; we only pay for actual reads/writes. S3 Lifecycle Policies: Automatically move old build artifacts and logs to S3 Glacier Deep Archive. Lambda Power Tuning: Optimize memory allocation to find the \u0026ldquo;sweet spot\u0026rdquo; between cost and performance. Budgets \u0026amp; Alarms: An AWS Budget alert is set at $15.00 to notify the team via email immediately if costs exceed the threshold. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": "During my internship, I participated in three events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AI-Driven Development Life Cycle: Reimagining Software Engineering\nDate \u0026amp; Time: 2:00 PM - 4:30 PM, Friday, October 3rd, 2025\nLocation: AWS Event Hall, L26 Bitexco Tower, HCMC\nRole: Attendee\nBrief Description: Workshop organized by AWS GenAI Builder Club focusing on how generative AI transforms the software development lifecycle. Featured demonstrations of Amazon Q Developer by Toan Huynh and Kiro tool by My Nguyen.\nOutcomes/Value Gained: Learned structured AI-DLC methodology, prompt engineering techniques for software development, and hands-on experience with AI-assisted development tools. Gained insights into spec-driven development approach and practical implementation strategies for AI-enhanced productivity.\nEvent 2 Event Name: Data Science on AWS Workshop\nDate \u0026amp; Time: 9:30 - 11:45 AM, October 18, 2025\nLocation: Hall A - FPTU HCMC\nRole: Attendee\nBrief Description: Educational workshop hosted by FPT University focusing on Machine Learning fundamentals and AWS AI/ML ecosystem. Led by Van Hoang Kha (Cloud Solutions Architect) and Bach Doan Vuong (Cloud DevOps Engineer).\nOutcomes/Value Gained: Acquired foundational knowledge about ML types (supervised, unsupervised, reinforcement learning), understanding of ML project lifecycle, and practical insights into AWS AI/ML services including the 3-tier ML stack architecture for scalable data science solutions.\nEvent 3 Event Name: Workshop: Secure Your Applications - AWS Perimeter Protection\nDate \u0026amp; Time: Full-day workshop, Tuesday, November 19, 2025\nLocation: AWS Training Center, Ho Chi Minh City\nRole: Attendee\nBrief Description: Hands-on technical workshop by AWS Vietnam focusing on edge security services and perimeter protection strategies. Instructed by Nguyen Gia Hung (Head of SA VN), Julian Ju and Kevin Lim (Regional Edge Security Specialists).\nOutcomes/Value Gained: Mastered AWS WAF configuration for protecting web applications from SQL Injection and XSS attacks, implemented AWS Shield for DDoS protection, and learned edge security architecture patterns. Gained practical experience through hands-on labs configuring security rules and understanding perimeter defense strategies.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.4-ec2/",
	"title": "Launch EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Launch EC2 Instance We will create a server that simulates a web application and pre-install necessary tools.\nSteps Access EC2 Console Open AWS Management Console and select EC2 service. Select Launch instances. Configure Instance Details Name: Set as Web-Server-Test OS Images: Select Amazon Linux 2023 AMI Instance type: Select t2.micro or t3.micro Key pair: Select \u0026ldquo;Proceed without a key pair\u0026rdquo; (We will use Session Manager, no need for SSH Key) Configure Network Settings\nLeave as default (ensure it\u0026rsquo;s in Public Subnet with Public IP) Configure Advanced details\nIAM instance profile: Select EC2-Monitor-AutoFix-Role created in step 1 Configure User Data Expand the Advanced details section Copy and paste the following script into the User Data field to automatically install Agent and testing tools: #!/bin/bash dnf update -y dnf install amazon-cloudwatch-agent stress -y Launch Instance Click Launch instance Wait a few minutes for the Instance to transition to Running state "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Master advanced AWS services including auto-scaling, monitoring, networking, and database services. Gain hands-on experience with AWS infrastructure management and optimization. Understand content delivery, edge computing, and hybrid cloud architectures. Develop expertise in NoSQL databases, caching, and DNS management. Practice advanced networking concepts including VPC peering and routing. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Complete Lab: Scaling Applications with EC2 Auto Scaling\n- Learn auto-scaling policies and triggers 06/10/2025 06/10/2025 AWS Educate Lab Guide + EC2 Auto Scaling Documentation 2 - Complete Lab: Monitoring with Amazon CloudWatch\n- Set up metrics, alarms, and dashboards 07/10/2025 07/10/2025 AWS Educate Lab Guide + CloudWatch Documentation 3 - Complete Lab: Hybrid DNS Management with Amazon Route 53\n- Complete Lab: Command Line Operations with AWS CLI 08/10/2025 08/10/2025 AWS Educate Lab Guide + Route 53 \u0026amp; CLI Documentation 4 - Complete Lab: NoSQL Database Essentials with Amazon DynamoDB\n- Complete Lab: In-Memory Caching with Amazon ElastiCache 09/10/2025 09/10/2025 AWS Educate Lab Guide + DynamoDB \u0026amp; ElastiCache Documentation 5 - Complete Lab: Networking on AWS Workshop\n- Advanced VPC configurations and security groups 10/10/2025 10/10/2025 AWS Educate Lab Guide + VPC Documentation 6 - Complete Lab: Content Delivery with Amazon CloudFront\n- Complete Lab: Edge Computing with CloudFront and Lambda@Edge 11/10/2025 11/10/2025 AWS Educate Lab Guide + CloudFront \u0026amp; Lambda@Edge Documentation 7 - Complete Lab: Network Integration with VPC Peering\n- Write Week 5 Worklog and documentation 12/10/2025 12/10/2025 AWS Educate Lab Guide + VPC Peering Documentation Week 5 Achievements: Completed advanced AWS infrastructure labs:\nEC2 Auto Scaling: Implemented automatic scaling policies, configured launch templates, and tested scaling triggers. Amazon CloudWatch: Set up comprehensive monitoring, created custom metrics, configured alarms, and built dashboards. Amazon Route 53: Managed DNS routing, implemented health checks, and configured hybrid DNS solutions. AWS CLI: Mastered command-line operations, automation scripts, and infrastructure management via CLI. Completed database and caching labs:\nAmazon DynamoDB: Designed NoSQL database schemas, implemented queries, and optimized performance. Amazon ElastiCache: Deployed in-memory caching solutions, configured Redis/Memcached clusters. Completed networking and content delivery labs:\nAWS Networking Workshop: Advanced VPC configurations, subnets, route tables, and security groups. Amazon CloudFront: Implemented global content delivery networks, configured distributions and caching policies. Lambda@Edge: Deployed edge computing functions for content customization and performance optimization. VPC Peering: Established secure network connections between VPCs across regions and accounts. Technical expertise developed:\nInfrastructure automation and scalability planning. Monitoring and observability best practices. NoSQL database design and caching strategies. Advanced networking and content delivery optimization. Edge computing and serverless architectures. Week 5 Reflections: Auto Scaling taught me how to build resilient applications that automatically respond to demand changes. CloudWatch monitoring provided deep insights into application performance and helped me understand observability best practices. Route 53 showed me the complexity and importance of DNS management in hybrid cloud environments. DynamoDB opened my eyes to the power and flexibility of NoSQL databases for modern applications. ElastiCache demonstrated how in-memory caching can dramatically improve application performance. Advanced networking labs deepened my understanding of VPC architecture and secure cloud connectivity. CloudFront and Lambda@Edge revealed the potential of edge computing for global application delivery. This week significantly expanded my AWS expertise from basic services to enterprise-level infrastructure management. \u0026hellip; "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.5-cloudwatch-agent/",
	"title": "Configure CloudWatch Agent",
	"tags": [],
	"description": "",
	"content": "Configure CloudWatch Agent By default, EC2 does not monitor RAM (Memory) metrics. We need to configure the Agent to collect this metric.\nSteps Access EC2 Instance via Session Manager In the EC2 instance list, select Web-Server-Test Click Connect Select the Session Manager tab Click Connect to open the command-line interface Create Agent Configuration File Create the configuration file using the following command (Copy the entire block and paste into terminal): sudo tee /opt/aws/amazon-cloudwatch-agent/bin/config.json \u0026lt;\u0026lt;EOF { \u0026#34;agent\u0026#34;: { \u0026#34;metrics_collection_interval\u0026#34;: 60, \u0026#34;run_as_user\u0026#34;: \u0026#34;root\u0026#34; }, \u0026#34;metrics\u0026#34;: { \u0026#34;metrics_collected\u0026#34;: { \u0026#34;mem\u0026#34;: { \u0026#34;measurement\u0026#34;: [ \u0026#34;mem_used_percent\u0026#34; ], \u0026#34;metrics_collection_interval\u0026#34;: 60 } } } } EOF Start Agent to Load Configuration Run the following command: sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json You have successfully configured CloudWatch Agent to monitor the memory (RAM) metrics of your EC2 instance.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.5-team/",
	"title": "Team Structure",
	"tags": [],
	"description": "",
	"content": "5. Team Structure 5.1 Project Stakeholders \u0026amp; Sponsors Role Name Description Partner Executive Sponsor Nguyễn Gia Hưng Project Mentor / Supervisor at First Cloud Journey \u0026amp; AWS Vietnam. Responsible for guidance and technical mentorship. Project Stakeholder FPT University HCMC Academic institution validating the system\u0026rsquo;s practical applicability and educational value. 5.2 Partner Project Team (SPICA) Team SPICA consists of 4 core members from FPT University, specializing in IoT, Cloud Computing, and Software Engineering.\nName Role Core Responsibilities Phạm Viết Lợi IoT core \u0026amp; Firmware Engineer • Hardware Architecture: Component selection (ESP32, AS608, MQ-3) and circuit design.\n• Embedded Coding: Developing C++/PlatformIO firmware for sensor reading and device logic.\n• Edge Security: Implementing fingerprint auth flows on the device. Đặng Đình Bắc Cloud Architect (Backend) • Serverless Computing: Design and implementation of AWS Lambda functions (Python).\n• Database Design: DynamoDB schema modeling and optimization.\n• IaC: Managing infrastructure via Terraform and GitHub Actions. Trần Quốc Dinh IoT Cloud \u0026amp; Fullstack Engineer • IoT Connectivity: Configuring AWS IoT Core, MQTT Topics, and Rules Engine.\n• Integration: Bridging the gap between Edge devices and the Web Frontend.\n• Frontend Support: Assisting in API integration and UI logic. Dương Hải Nam Frontend Developer • UI/UX Design: Creating the Public Lookup Portal and Admin Dashboard.\n• Web Development: Building the SPA using React/Vue.js.\n• Deployment: Configuring AWS Amplify hosting and CI/CD for the frontend. 5.3 Communication Plan To ensure smooth collaboration, Team SPICA adheres to the following communication cadence:\nDaily Stand-up: 15 minutes every morning to discuss progress and blockers. Weekly Sprint Review: Every Friday to demonstrate completed features to the Mentor. Tools: Source Control: GitHub (Monorepo). Task Management: Trello / Jira / GitHub Projects. Communication: Slack / Discord / Microsoft Teams. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "CloudWatch Monitoring and Auto-Recovery System Overview In this lab, you will build a monitoring and auto-recovery system using AWS CloudWatch, EventBridge, and Systems Manager. This system will continuously monitor the RAM usage of an EC2 instance and automatically restart the server when memory exceeds the 80% threshold.\nBenefits of This System Continuous Monitoring: CloudWatch Agent collects memory metrics every 60 seconds Real-time Alerts: SNS Topic sends email notifications when an Alarm is triggered Automatic Recovery: EventBridge Rule triggers Systems Manager to automatically restart the instance No Manual Intervention: The system operates 24/7 without user intervention Content Workshop overview Prerequisite Create IAM Role Launch EC2 Instance Configure CloudWatch Agent Create CloudWatch Alarm Setup EventBridge Rule Testing (Chaos Testing) Cleanup Resources "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Learn advanced AWS Security services for enterprise applications. Implement credential management and application protection strategies. Complete and finalize the internship proposal document. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Lab 1: Credentials Management with AWS Secrets Manager + Create secret storage + Configure automatic rotation + Integrate with applications 13/10/2025 13/10/2025 AWS Secrets Manager Documentation 2 - Lab 2: Application Protection with AWS WAF + Configure web ACLs + Set up rate limiting + Block malicious requests 14/10/2025 14/10/2025 AWS WAF User Guide 3 - Lab 3: Threat Detection with AWS GuardDuty + Enable threat detection + Configure findings + Set up notifications 15/10/2025 15/10/2025 AWS GuardDuty Documentation 4 - Lab 4: Security Compliance with AWS Security Hub + Enable security standards + Review compliance findings + Generate reports 16/10/2025 16/10/2025 AWS Security Hub User Guide 5 - Complete Internship Proposal + Finalize project objectives + Define deliverables + Set timeline and milestones 17/10/2025 17/10/2025 FCJ Proposal Template 6 - Weekend Review \u0026amp; Documentation + Review all security lab implementations + Document lessons learned + Prepare presentation materials 18/10/2025 18/10/2025 Personal Documentation 7 - Weekly Summary \u0026amp; Planning + Write comprehensive worklog + Analyze security findings + Plan next week activities 19/10/2025 19/10/2025 FCJ Worklog Template Week 6 Achievements: AWS Security Services Implementation:\nAWS Secrets Manager Lab:\nSuccessfully created and configured secure credential storage Implemented automatic password rotation for RDS database Integrated secret retrieval with Lambda functions Learned best practices for managing API keys and database credentials AWS WAF (Web Application Firewall) Lab:\nConfigured web Access Control Lists (ACLs) for application protection Implemented rate limiting rules to prevent DDoS attacks Set up geo-blocking and IP reputation filtering Successfully blocked SQL injection and XSS attack patterns AWS GuardDuty Lab:\nEnabled intelligent threat detection across AWS account Configured threat intelligence feeds and malware detection Set up CloudWatch Events integration for automated responses Analyzed security findings and threat indicators AWS Security Hub Lab:\nEnabled AWS Config and AWS Security Hub compliance monitoring Reviewed CIS AWS Foundations Benchmark findings Generated comprehensive security posture reports Implemented remediation strategies for critical findings Project Management:\nCompleted Internship Proposal: Defined clear project objectives and scope Established deliverables and success criteria Created detailed timeline with weekly milestones Identified required resources and potential challenges Key Learning Outcomes:\nGained comprehensive understanding of AWS security architecture Learned to implement defense-in-depth security strategies Developed skills in threat detection and incident response Mastered compliance monitoring and reporting techniques Enhanced project planning and documentation abilities Technical Skills Acquired:\nSecurity policy configuration and management Automated threat response implementation Compliance framework understanding Risk assessment and mitigation strategies Weekend Activities \u0026amp; Review:\nSaturday - Documentation \u0026amp; Analysis:\nReviewed and analyzed all security lab implementations Documented detailed steps and configurations for future reference Created comparison charts between different security services Identified potential integration opportunities between services Sunday - Summary \u0026amp; Planning:\nWrote comprehensive weekly worklog with technical details Analyzed security findings and created improvement recommendations Prepared presentation materials for next week\u0026rsquo;s progress review Planned integration strategies for upcoming advanced AWS topics "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.6-cloudwatch-alarm/",
	"title": "Create CloudWatch Alarm",
	"tags": [],
	"description": "",
	"content": "Create CloudWatch Alarm We will create an alarm when RAM usage exceeds 80%.\nSteps Access CloudWatch Console\nOpen AWS Management Console and select CloudWatch service. Create a new Alarm\nSelect All alarms -\u0026gt; Create alarm Select Metric Click Select metric Select CWAgent -\u0026gt; ImageId, InstanceId, InstanceType Find the mem_used_percent metric for the Web-Server-Test instance Configure Conditions Statistic: Average Period: 1 minute Threshold type: Static Threshold value: 80 (Greater than 80%) Configure Actions Notification: Select Create new topic Topic name: Set as Admin-Alerts Email: Enter your email Click Create topic Important note: Do not select \u0026ldquo;EC2 Action\u0026rdquo; here (because RAM metric is a custom metric and does not support direct reboot). We will use EventBridge instead. Remember to check your email to Confirm Subscription. Name the Alarm Alarm name: High-Memory-Auto-Reboot Click Create alarm You have successfully created a CloudWatch Alarm to monitor the RAM usage of your EC2 instance.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.6-resources/",
	"title": "Resources &amp; Estimates",
	"tags": [],
	"description": "",
	"content": "6. Resources \u0026amp; Cost Estimates 6.1 Resource Rate Card Note: The rates below are estimated market values for calculation purposes. As this is an academic capstone project, the labor cost represents an \u0026ldquo;in-kind\u0026rdquo; contribution from the students.\nResource Role Assigned Member(s) Est. Rate (USD/hr) IoT Lead / Firmware Phạm Viết Lợi $35 Cloud Architect Đặng Đình Bắc $40 IoT Cloud Integration Trần Quốc Dinh $35 Frontend Developer Dương Hải Nam $30 6.2 Resource Allocation Matrix This table estimates the total hours required per phase for each specialized role.\nProject Phase IoT / Firmware (Lợi) Cloud Backend (Bắc) Integration (Dinh) Frontend (Nam) Total Hours I. Design \u0026amp; Foundation 20 25 20 10 75 II. Firmware Dev 60 10 30 0 100 III. Backend Services 10 60 40 10 120 IV. Frontend Dev 5 10 20 60 95 V. Testing \u0026amp; Security 20 20 20 20 80 VI. Handover 10 10 10 10 40 TOTAL HOURS 125 135 140 110 510 Total Estimated Labor Value: $$(125 \\times 35) + (135 \\times 40) + (140 \\times 35) + (110 \\times 30) = \\mathbf{$17,975}$$\n6.3 Cost Contribution Distribution Party Contribution Type Est. Value (USD) % Contribution Customer (FPT Uni) Hardware Funding (Sensors, ESP32) ~$100 \u0026lt; 1% Partner (Team SPICA) Engineering Labor (Design, Dev, Test) ~$17,975 ~99% AWS Education Cloud Credits (Hosting \u0026amp; Services) ~$50 \u0026lt; 1% TOTAL ~$18,125 100% "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at First Cloud Journey (AWS Vietnam) from September 2025 to November 2025, I had the opportunity to learn, practice, and apply cloud computing knowledge in a real-world AWS environment.\nI participated in a 12-week intensive AWS learning program, building an IoT Smart Device Management System while mastering 10+ core AWS services including Lambda, API Gateway, DynamoDB, S3, CloudFront, IoT Core, and implementing Infrastructure as Code with Terraform. Through this hands-on project, I significantly improved my skills in cloud architecture design, serverless development, DevOps automation, security implementation (IAM, WAF), and AWS best practices.\nIn terms of work ethic, I demonstrated strong self-directed learning, consistently completed weekly milestones, maintained detailed documentation throughout the project, and actively participated in AWS community events and workshops to deepen my cloud computing knowledge.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Master advanced AWS storage and container orchestration services. Complete technical architecture diagrams for the project proposal. Prepare comprehensively for Week 8 assessment and evaluation. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Lab 1: Data Protection with AWS Backup + Configure backup plans + Set up cross-region backup + Test restore procedures 20/10/2025 20/10/2025 AWS Backup User Guide 2 - Lab 2: Snapshot Automation with Amazon EBS Data Lifecycle Manager + Create lifecycle policies + Configure automated snapshots + Manage retention rules 21/10/2025 21/10/2025 Amazon EBS Data Lifecycle Manager Guide 3 - Lab 3: Container Orchestration with Amazon ECS + Create ECS clusters + Configure task definitions + Deploy containerized applications 22/10/2025 22/10/2025 Amazon ECS Developer Guide 4 - Lab 4: Shared Storage with Amazon EBS Multi-Attach + Configure multi-attach volumes + Set up cluster file systems + Test concurrent access 23/10/2025 23/10/2025 Amazon EBS Multi-Attach Documentation 5 - Complete AWS Technical Architecture Diagrams + Design system architecture + Create network topology + Document service integrations 24/10/2025 24/10/2025 AWS Architecture Center 6 - Weekend Review \u0026amp; Study + Review all previous weeks\u0026rsquo; materials + Create comprehensive study notes + Practice hands-on scenarios 25/10/2025 25/10/2025 Personal Study Materials 7 - Assessment Preparation + Final review and practice tests + Consolidate knowledge gaps + Prepare for Week 8 evaluation 26/10/2025 26/10/2025 FCJ Assessment Guidelines Week 7 Achievements: Advanced AWS Services Implementation:\nAWS Backup Lab:\nSuccessfully configured comprehensive backup plans for EC2 instances and RDS databases Implemented cross-region backup strategies for disaster recovery Tested restore procedures and validated backup integrity Learned backup retention policies and cost optimization strategies Amazon EBS Data Lifecycle Manager Lab:\nCreated automated snapshot lifecycle policies for EBS volumes Configured cross-region snapshot copying for data durability Implemented retention rules to manage storage costs effectively Set up tag-based snapshot automation for organized data management Amazon ECS Container Orchestration Lab:\nCreated and configured ECS clusters with EC2 and Fargate launch types Developed comprehensive task definitions with resource specifications Successfully deployed multi-container applications with load balancing Implemented service auto-scaling and health check configurations Amazon EBS Multi-Attach Lab:\nConfigured EBS volumes with multi-attach capabilities for shared storage Set up cluster-aware file systems (OCFS2) for concurrent access Tested high-availability scenarios with multiple EC2 instances Implemented data consistency and locking mechanisms Project Development:\nCompleted AWS Technical Architecture Diagrams: Designed comprehensive system architecture for the internship project Created detailed network topology with VPC, subnets, and security groups Documented service integrations and data flow between components Prepared technical specifications for implementation phase Assessment Preparation:\nComprehensive Study and Review: Consolidated knowledge from all 7 weeks of AWS learning Created detailed study notes covering all major AWS services Practiced hands-on scenarios and troubleshooting exercises Identified and addressed knowledge gaps through targeted review Key Learning Outcomes:\nMastered advanced storage management and data protection strategies Gained expertise in container orchestration and microservices architecture Developed skills in disaster recovery planning and business continuity Enhanced understanding of AWS cost optimization and resource management Improved technical documentation and architecture design capabilities Technical Skills Acquired:\nAdvanced backup and disaster recovery implementation Container deployment and orchestration Storage optimization and lifecycle management System architecture design and documentation Assessment readiness and comprehensive AWS knowledge integration "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/2-proposal/2.7-acceptance/",
	"title": "Acceptance",
	"tags": [],
	"description": "",
	"content": "7. Acceptance 7.1 Acceptance Process To conclude the project, the acceptance process will follow these simple steps:\nSubmission: Team SPICA submits the Source Code, Deployment Scripts (Terraform), and Final Report to the Instructor/Customer. Review Period: The Customer has 5 business days to test and verify the system. Sign-off: If all criteria below are met, the Customer signs the Project Acceptance Form. 7.2 Acceptance Criteria The project is considered complete when the following 3 conditions are met:\nFunctional Edge Device:\nThe ESP32 successfully unlocks only when a registered fingerprint is scanned. The device sends alcohol and health data to AWS immediately after measurement. Working Web Portal:\nViolation records appear on the public website within 5 seconds of recording. Users can successfully search for violations using a valid ID (CCCD). Deployable Code:\nThe backend infrastructure can be re-created automatically using the provided Terraform scripts without errors. 7.3 Rejection \u0026amp; Fixes If any bug is found (e.g., device fails to connect, website crashes), the Customer must notify Team SPICA within the review period. The team has 3 business days to fix the issue and resubmit for approval. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.7-eventbridge-rule/",
	"title": "Setup EventBridge Rule",
	"tags": [],
	"description": "",
	"content": "Setup EventBridge Rule This step connects the Alarm with the Reboot action through Systems Manager.\nSteps Access Amazon EventBridge Console Open AWS Management Console and select EventBridge service. Create a new Rule Select Rule with an event pattern Select Rules -\u0026gt; Create rule Configure Events (Step 4a: Triggering Events) In the Event section on the left, select AWS SERVICE EVENT Search event: CloudWatch Alarm State Change Drag and drop into the Triggering Event box Configure Targets (Step 4b: Targets) On the left section, select the Targets section Search target: EC2 Reboot Instance Drag and drop into the Targets box In the Target configuration section, assign the EC2 instance ID that you created in the previous steps Select Create a new role for this specific resource Finish Click Create rule to complete Name: Rule-Reboot-On-High-Memory You have successfully set up an EventBridge Rule to automatically restart the EC2 instance when RAM exceeds 50%.\n"
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nHere, you can freely share your personal opinions about your experience participating in the First Cloud Journey program. This will help the FCJ team improve any shortcomings based on the following aspects:\nOverall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Would you like to continue this program in the future? Any other comments (free sharing): "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Build Core Pipeline: Sensor data flows to Database. Complete hardware assembly and test all sensors. Establish AWS IoT Core connection. Tasks to be carried out this week: Day Task Start Date Completion Date 1 - Assemble circuit on Breadboard: ESP32 + MQ-3 + MAX30102 + Keypad + LCD + AS608 - Unit test each sensor individually 27/10/2025 28/10/2025 3 - Write ESP32 firmware: Read MQ-3 (alcohol) and MAX30102 (heart rate) data - Implement Keypad input and LCD display 29/10/2025 30/10/2025 5 - Package sensor data as JSON - Implement MQTT publish to AWS IoT Core 31/10/2025 31/10/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 6 Team Meeting #1Hardware \u0026amp; Firmware Sprint 01/11/2025 Offline Focus:• Debug sensor integration issues• Test MQTT connection to AWS IoT Core• Review firmware code qualityResults:✓ All sensors working stable✓ MQTT successfully publishing data Day Task Start Date Completion Date 7 - Setup AWS IoT Core: Create Thing, Policy, Certificate - Configure IoT Rule for data routing - Write ProcessViolationFunction Lambda - Create DynamoDB ViolationsDB table - Test end-to-end: Sensor → DynamoDB - Write worklog and review week progress 02/11/2025 02/11/2025 Week 8 Achievements: Hardware: All sensors operational on breadboard. Firmware: ESP32 reading sensors and publishing MQTT successfully. AWS: IoT Core configured, Lambda processing data, DynamoDB storing violations. Deliverable: Blow into MQ-3 sensor → New record appears in DynamoDB. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.8-test/",
	"title": "Testing (Chaos Testing)",
	"tags": [],
	"description": "",
	"content": "Testing (Chaos Testing) Simulate a memory overflow issue to test the system.\nSteps Return to the EC2 Session Manager interface\nAccess EC2 Console Select the Web-Server-Test instance Click Connect Select the Session Manager tab -\u0026gt; Connect Run stress command to push RAM to alarm level\nRun the following command (approximately 850MB for t2.micro): stress --vm 1 --vm-bytes 850M --vm-hang 300 Observe the Results On CloudWatch Alarm:\nStatus changes to red (ALARM) In Email:\nReceive alert from SNS On Session Manager:\nConnection is disconnected (server is restarting) On EC2 Console:\nInstance status changes to Stopping then Running After Instance restarts:\nAlarm will automatically return to OK status Conclusion You have successfully built an automated system for issue recovery! When memory exceeds 80%, the system will automatically:\nSend alert via email Trigger EventBridge Rule Call Systems Manager to restart the instance Instance automatically restarts and returns to OK status "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Implement Hybrid Authentication (Fingerprint + Cloud). Build API for data retrieval (Dashboard \u0026amp; Search). Complete business logic layer. Tasks to be carried out this week: Day Task Start Date Completion Date 1 - Create DynamoDB DeviceOfficerMap_Pool table - Write Lambda AuthorizeFunction for fingerprint verification 03/11/2025 03/11/2025 2 - Configure IoT Rule for authorization flow - Update ESP32 firmware: Scan fingerprint → Send SlotID → Receive unlock command 04/11/2025 04/11/2025 4 - Create 2 GSI on ViolationsDB (Dashboard \u0026amp; Search indexes) - Write Lambda GetDashboardFunction and SearchByCCCDFunction 06/11/2025 07/11/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 6 Team Meeting #2API Integration Testing 08/11/2025 Offline Focus:• Test fingerprint authentication end-to-end• Debug API Lambda functions• Validate GSI query performanceResults:✓ Fingerprint auth working correctly✓ APIs returning proper JSON data Day Task Start Date Completion Date 7 - Setup API Gateway: Create /dashboard and /search/{cccd} endpoints - Enable CORS configuration - Integration test: Browser → API → JSON response - Write worklog and review week progress 09/11/2025 09/11/2025 Week 9 Achievements: Authentication: Fingerprint scan → Device unlocks successfully. API Layer: Dashboard and Search endpoints operational. Database: GSI indexes optimized for query patterns. Deliverable: Browser API call returns violation data in JSON format. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/5-workshop/5.9-clean-material/",
	"title": "Cleanup Resources",
	"tags": [],
	"description": "",
	"content": "Cleanup Resources After completing the above steps, you should clean up AWS resources to avoid unnecessary costs.\nSteps Delete EventBridge Rule\nAccess Amazon EventBridge Console Select Rules Find and select Rule-Reboot-On-High-Memory Click Delete Delete CloudWatch Alarm\nAccess CloudWatch Console Select All alarms Find and select High-Memory-Auto-Reboot Click Delete alarm Delete SNS Topic\nAccess SNS Console Select Topics Find and select Admin-Alerts Click Delete Delete EC2 Instance\nAccess EC2 Console Select Instances Find and select Web-Server-Test Click Instance State -\u0026gt; Terminate Confirm Terminate Delete IAM Role\nAccess IAM Console Select Roles Find and select EC2-Monitor-AutoFix-Role Click Delete Confirm Delete role Important Notes Make sure you no longer need these resources before deleting Deletion is permanent and cannot be recovered After deletion, you will not be charged for these resources "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Build web interface for system interaction. Deploy frontend to S3 + CloudFront. Complete end-to-end integration testing. Tasks to be carried out this week: Day Task Start Date Completion Date 1 - Create index.html, style.css, app.js - Implement fetch() logic for Dashboard and Search APIs - Display data in tables and charts 10/11/2025 11/11/2025 3 - Upload frontend to S3 bucket - Enable Static Website Hosting - Configure CloudFront distribution for HTTPS 12/11/2025 12/11/2025 4 - End-to-end integration test: Device unlock → Measure violation → Enter CCCD → Web auto-update - Fix UI/UX bugs - Performance optimization 13/11/2025 14/11/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 6 AWS Cloud Mastery Series #1Generative AI with Amazon Bedrock 15/11/2025 Offline Key Topics:• RAG architecture for connecting LLM with enterprise data• Building AI Agents with Runtime and Memory capabilities• Few-shot prompting techniques for optimal AI resultsLearning Outcomes:✓ Understood RAG (Retrieval-Augmented Generation) architecture✓ Hands-on experience building AI Agents with task automation✓ Mastered few-shot prompting optimization techniques 6 Team Meeting #3Frontend Demo \u0026amp; Testing 15/11/2025 Offline Focus:• Demo web interface to stakeholders• Collect feedback on UI/UX• Stress test API loadResults:✓ Web displaying real-time data correctly✓ Identified minor UI improvements Day Task Start Date Completion Date 7 - Apply UI/UX improvements - Final staging deployment - Documentation: User guide and API documentation - Write worklog and review week progress 16/11/2025 16/11/2025 Week 10 Achievements: Frontend: Responsive web interface with tables and charts. Deployment: Public website via CloudFront with HTTPS. Integration: Full workflow tested successfully. Deliverable: Live website displaying device data correctly. "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Implement Infrastructure as Code with Terraform. Establish CI/CD pipelines for automation. Apply security best practices (WAF, monitoring). Attend AWS Cloud Mastery Series workshops. Tasks to be carried out this week: Day Task Start Date Completion Date 1 - Write Terraform code for all resources: Lambda, API Gateway, DynamoDB, IoT Core\n- Test infrastructure deployment via Terraform 17/11/2025 18/11/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 1 AWS Cloud Mastery Series #2DevOps \u0026amp; Container Orchestration 17/11/2025 Offline Key Topics:• Containerization: Docker vs VM comparison, Dockerfile optimization• Orchestration: Amazon ECS architecture (Fargate vs EC2) vs Kubernetes• CI/CD: CloudFormation and CodePipeline for automated deploymentLearning Outcomes:✓ Mastered containerization concepts and Docker best practices✓ Understood ECS orchestration and deployment strategies✓ Implemented automated CI/CD pipelines 3 Workshop: Secure Your ApplicationsAWS Perimeter Protection (Edge Security)Instructors:• Mr. Nguyen Gia Hung (Head of SA VN)• Mr. Julian Ju (Regional Edge Specialist)• Mr. Kevin Lim (Regional Edge Specialist) 19/11/2025 Offline Key Topics:• Hands-on Lab: AWS WAF configuration for SQL Injection/XSS protection• Resilience: AWS Shield implementation for DDoS attack mitigation• Edge security best practices and architecture patternsLearning Outcomes:✓ Configured AWS WAF rules for web application protection✓ Implemented AWS Shield for DDoS defense✓ Understood perimeter security architecture design Day Task Start Date Completion Date 5 - Setup AWS CodePipeline connected to GitHub\n- Configure auto-deploy on Terraform push - Setup AWS Amplify for Frontend CI/CD 21/11/2025 21/11/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 6 Team Meeting #4IaC \u0026amp; Pipeline Review 22/11/2025 Offline Focus:• Review Terraform code quality• Test CI/CD pipeline triggers• Security audit checklistResults:✓ IaC successfully deploying all resources✓ Pipeline auto-deploying on code push Day Task Start Date Completion Date 7 - Enable AWS WAF on API Gateway/CloudFront\n- Configure CloudWatch Dashboard for monitoring - Setup alarms for system errors - Write worklog and review week progress 23/11/2025 23/11/2025 Week 11 Achievements: 🏗️ Infrastructure as Code Terraform Implementation: All AWS resources defined as code Version-controlled infrastructure Repeatable deployments 🔄 CI/CD Automation Pipeline Established: Auto-deploy on GitHub push Frontend via AWS Amplify Backend via CodePipeline 🔒 Security \u0026amp; Monitoring AWS WAF: Protecting APIs from common attacks. CloudWatch: Real-time monitoring dashboard. 🤖 AWS Workshops Attended Generative AI with Amazon Bedrock:\nRAG architecture for enterprise AI AI Agents with Runtime \u0026amp; Memory Few-shot prompting optimization DevOps \u0026amp; Container Orchestration:\nDocker vs VM, Dockerfile optimization Amazon ECS \u0026amp; Kubernetes orchestration CI/CD with CloudFormation \u0026amp; CodePipeline Security Workshop - AWS Perimeter Protection:\nAWS WAF: SQL Injection/XSS protection AWS Shield: DDoS mitigation Edge security architecture best practices "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Complete testing, tuning and optimization. Prepare comprehensive documentation. Record demo video and finalize deliverables. Attend AWS Cloud Mastery Series workshop. Tasks to be carried out this week: Day Task Start Date Completion Date 1 - Stress test: Run stability tests on full system - Calibrate sensors if error margin too large - Improve web UI/UX (CSS refinements) 24/11/2025 26/11/2025 4 - Write Final Report document - Update architecture diagram to latest version - Prepare technical documentation 27/11/2025 27/11/2025 Day Event/Task Date Format Key Activities \u0026amp; Outcomes 6 AWS Cloud Mastery Series #3Advanced Security \u0026amp; Networking Architecture 29/11/2025 Offline Key Topics:Identity \u0026amp; Access Management:• Large-scale permission management with Service Control Policies (SCPs)• Short-term credentials implementation using AWS STS (Security Token Service)• Best practices for least-privilege access at organization levelNetwork Defense Architecture:• Defense-in-Depth architecture design principles• East-West traffic control using AWS Network Firewall• Internal traffic inspection and threat preventionMicrosegmentation Strategy:• Security Group Referencing techniques for fine-grained access control• Transit Gateway integration for multi-VPC security• Implementing zero-trust network architectureLearning Outcomes:✓ Mastered enterprise-scale identity governance with SCPs✓ Implemented secure temporary access patterns with STS✓ Designed defense-in-depth network architectures✓ Applied Network Firewall for internal traffic inspection✓ Configured microsegmentation using Security Group Referencing✓ Integrated Transit Gateway for secure multi-VPC connectivity 6 Team Meeting #5Final Review \u0026amp; Rehearsal 29/11/2025 Offline Focus:• Review all deliverables checklist• Rehearse demo presentation• Final bug fixes and polishResults:✓ All components working stably✓ Documentation complete✓ Ready for submission Day Task Start Date Completion Date 7 - Record product demo video - Package all source code for submission - Final submission: Source code, Report, Video - Write worklog and review week progress 30/11/2025 30/11/2025 Week 12 Achievements: ✅ Testing \u0026amp; Quality Assurance Stress Testing: System stable under load. Sensor Calibration: Accuracy within acceptable range. UI Polish: Professional web interface. 📄 Documentation Complete Final Report: Comprehensive project documentation. Architecture Diagram: Updated to v7 with all components. API Documentation: Complete endpoint reference. 🎥 Deliverables Ready Demo Video: Showcasing full workflow. Source Code: Clean, documented, version-controlled. Deployment: Production system live and operational. 🎓 Workshop Attended Advanced Security \u0026amp; Networking: Enterprise IAM: SCPs for multi-account permission management\nAWS STS: Temporary credentials \u0026amp; cross-account access\nLeast Privilege: Zero-trust IAM policies at scale\nDefense-in-Depth: Multi-layer network security architecture\nAWS Network Firewall: East-West traffic inspection \u0026amp; threat prevention\nMicrosegmentation: Security Group Referencing \u0026amp; Transit Gateway integration\nDeployed centralized firewall management architecture Advanced Threat Protection:\nBlocked malicious traffic between internal resources Applied deep packet inspection for lateral movement prevention Configured custom rule sets for organization-specific threats Integrated with AWS Firewall Manager for centralized policies 🌐 Microsegmentation \u0026amp; Zero-Trust Networking Security Group Referencing:\nImplemented microsegmentation using Security Group references Created dynamic, self-updating security rules Reduced management overhead with logical security boundaries Applied fine-grained access control between application tiers Transit Gateway Integration:\nDesigned scalable multi-VPC connectivity architecture Centralized network routing and security inspection Implemented hub-and-spoke network topology Applied Transit Gateway security best practices Zero-Trust Network Architecture:\nEliminated implicit trust between network segments Verified every connection regardless of source location Implemented identity-based access controls at network layer Applied continuous verification and least-privilege principles 🎯 Advanced Security Competencies Enterprise-Scale Security: Mastered security patterns applicable to large, complex AWS environments Architectural Design: Gained expertise in designing secure, scalable cloud architectures Best Practices: Applied AWS Well-Architected Framework security pillar principles Compliance: Understood security controls required for regulated industries "
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://dinhtqse.github.io/AWS_FCJ_WSReports/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]